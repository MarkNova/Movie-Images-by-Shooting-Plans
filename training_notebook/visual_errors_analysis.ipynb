{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7715510,"sourceType":"datasetVersion","datasetId":4506003},{"sourceId":19392,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":16089}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport matplotlib.pyplot as plt\nfrom matplotlib.font_manager import FontProperties\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-23T01:07:54.892509Z","iopub.execute_input":"2024-03-23T01:07:54.892840Z","iopub.status.idle":"2024-03-23T01:07:55.868978Z","shell.execute_reply.started":"2024-03-23T01:07:54.892815Z","shell.execute_reply":"2024-03-23T01:07:55.868193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torchvision.models import efficientnet_v2_s\nfrom torchvision import datasets, transforms ","metadata":{"execution":{"iopub.status.busy":"2024-03-23T01:07:55.870599Z","iopub.execute_input":"2024-03-23T01:07:55.870975Z","iopub.status.idle":"2024-03-23T01:08:02.444361Z","shell.execute_reply.started":"2024-03-23T01:07:55.870950Z","shell.execute_reply":"2024-03-23T01:08:02.443545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","metadata":{"execution":{"iopub.status.busy":"2024-03-23T01:08:02.445642Z","iopub.execute_input":"2024-03-23T01:08:02.446799Z","iopub.status.idle":"2024-03-23T01:08:02.475316Z","shell.execute_reply.started":"2024-03-23T01:08:02.446761Z","shell.execute_reply":"2024-03-23T01:08:02.474331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = torch.load('/kaggle/input/efficientnetv2_shots_by_plan/pytorch/73.14/1/model 73.14.pth')\nmodel.eval()\npass","metadata":{"execution":{"iopub.status.busy":"2024-03-23T01:08:02.477623Z","iopub.execute_input":"2024-03-23T01:08:02.477915Z","iopub.status.idle":"2024-03-23T01:08:04.066116Z","shell.execute_reply.started":"2024-03-23T01:08:02.477891Z","shell.execute_reply":"2024-03-23T01:08:04.065315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dir = \"/kaggle/input/movie-images-by-types-of-shooting-plans/data/validation\"\n\nval_transforms = transforms.Compose([\n                                    transforms.Resize((380, 380)),\n                                    transforms.ToTensor(),\n                                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ])\n\nval_dataset = datasets.ImageFolder(data_dir, val_transforms)\n\nval_loader = torch.utils.data.DataLoader(\n                                   val_dataset,\n                                   batch_size=32,\n                                   shuffle=True,\n                                   num_workers=2\n                                  ) ","metadata":{"execution":{"iopub.status.busy":"2024-03-23T01:08:04.067200Z","iopub.execute_input":"2024-03-23T01:08:04.067499Z","iopub.status.idle":"2024-03-23T01:08:04.744971Z","shell.execute_reply.started":"2024-03-23T01:08:04.067468Z","shell.execute_reply":"2024-03-23T01:08:04.743949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names = val_dataset.classes\nclass_names = [i.replace('%20', ' ') for i in class_names]","metadata":{"execution":{"iopub.status.busy":"2024-03-23T01:08:04.746215Z","iopub.execute_input":"2024-03-23T01:08:04.746539Z","iopub.status.idle":"2024-03-23T01:08:04.751053Z","shell.execute_reply.started":"2024-03-23T01:08:04.746512Z","shell.execute_reply":"2024-03-23T01:08:04.750165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def unnormalize(img):\n    img = img * torch.tensor([0.229, 0.224, 0.225])[:, None, None] + torch.tensor([0.485, 0.456, 0.406])[:, None, None]\n    return img\n\ndef visualize_model_errors(model, dataloader, device, class_names,  num_images=6):\n    was_training = model.training\n    model.eval()\n    images_so_far = 0\n    image_size = 9\n    fig = plt.figure(figsize=(image_size * 2, image_size * num_images / 2))\n    font_alplha = 0.8\n\n    with torch.no_grad():\n        for i, (inputs, labels) in enumerate(dataloader):\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n            back_color = 'darkslategray'\n            plt.subplots_adjust(wspace=0.032, hspace=0.0025)\n            fig.patch.set_facecolor('black')\n            for j in range(inputs.size()[0]):\n                if preds[j] != labels[j]:\n                    images_so_far += 1\n                    \n                    ax = plt.subplot(num_images//2, 2, images_so_far)\n                    ax.axis('off')\n    \n                    \n                    title = ' {}\\n'.format(class_names[labels[j]])\n                    ax.set_title(title,\n                                 pad=0,\n                                 y=0.97,\n                                 x=0,\n                                 color='goldenrod',\n                                 fontsize=25,\n#                                  fontweight='semibold',\n                                 backgroundcolor=back_color,\n                                 verticalalignment='top',\n                                 horizontalalignment='left',\n                                 fontstyle='oblique',\n                                 alpha=font_alplha)\n                    \n                    image = inputs.cpu().data[j]\n                    image = unnormalize(image)\n                    image = image.numpy().transpose((1, 2, 0))\n                    plt.imshow(image)\n\n                    predicted_probs, predicted_labels = torch.topk(torch.softmax(outputs, dim=1), 3, dim=1)\n                    predicted_probs = predicted_probs[j].cpu().numpy()\n                    predicted_labels = predicted_labels[j].cpu().numpy()\n                    text = ''\n                    for k in range(3):\n                        text += '{} ({:.2f}%)\\n'.format(class_names[predicted_labels[k]], predicted_probs[k]*100)\n                    \n                    ax.text(1,\n                            0.97,\n                            text,\n                            color='seashell',\n                            backgroundcolor=back_color,\n                            fontsize=16, verticalalignment='top',\n                            horizontalalignment='right',\n                            transform=ax.transAxes,\n                            fontstyle='italic',\n                            alpha=font_alplha)\n\n                    if images_so_far == num_images:\n                        model.train(mode=was_training)\n                        return\n        model.train(mode=was_training)","metadata":{"execution":{"iopub.status.busy":"2024-03-23T01:18:33.635664Z","iopub.execute_input":"2024-03-23T01:18:33.636576Z","iopub.status.idle":"2024-03-23T01:18:33.652934Z","shell.execute_reply.started":"2024-03-23T01:18:33.636539Z","shell.execute_reply":"2024-03-23T01:18:33.651844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_model_errors(model, val_loader, device, class_names, num_images=64)","metadata":{"execution":{"iopub.status.busy":"2024-03-23T01:18:45.292779Z","iopub.execute_input":"2024-03-23T01:18:45.293636Z","iopub.status.idle":"2024-03-23T01:19:12.845524Z","shell.execute_reply.started":"2024-03-23T01:18:45.293600Z","shell.execute_reply":"2024-03-23T01:19:12.844435Z"},"trusted":true},"execution_count":null,"outputs":[]}]}